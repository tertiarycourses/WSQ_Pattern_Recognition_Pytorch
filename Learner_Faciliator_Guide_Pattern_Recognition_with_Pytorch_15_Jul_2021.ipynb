{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Learner/Faciliator Guide - Pattern Recognition with Pytorch  - 15 Jul 2021",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "OBmwaDOqvU_-",
        "i9m_CaKBylPY",
        "XyAhWaDWMn8H",
        "u1qhtFgjH0ml",
        "5wwjxm4gH_Bf",
        "dtA2qbcygh6i",
        "1LXn1ZVJIn_k",
        "So5PZ3YhIwzL",
        "Q9wclFVOI01a",
        "mBw7dlX6JPVG",
        "Sjw3w75aLzN9",
        "9XYniWyCOpji",
        "SvelV5hrO2kI",
        "04GMNiP-P5jD",
        "2wNP54DhQF0_",
        "WhE7L8cvQPz2",
        "1ZJ4DgwtQUhK",
        "rIpnqun-Qhcw",
        "6xVeTe7aRx89",
        "S7wv4vI5eZjO",
        "1n5DkX1IIDOV",
        "FD736TNIIAkx",
        "4UGAZ04LIGaM",
        "5F4s6VqdaGmT",
        "3j3uo7mRHyBU",
        "-Kx1B_1KiGVz",
        "G2bmeqi8VidX",
        "AiGxc0Cz0Owk",
        "uV-2363H4uRP",
        "X_YfmD6K4w9T",
        "FxBNoYHFjZXt",
        "WGSeTI-vlDrz",
        "cSwx_QKPEBMH",
        "ozYdnTeaHo1n",
        "BYlbPLt0KOYL",
        "QxAntTWJKdJ7",
        "izOsDiDd3rON",
        "Kze0f3VXjIFa",
        "zcbo4QZ4QASi",
        "Jp8g6D76110Y",
        "nOmxuc8U1-Ca"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBmwaDOqvU_-"
      },
      "source": [
        "# Topic 2 Machine Learning for Regression and Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9m_CaKBylPY"
      },
      "source": [
        "## Introduction to Pytorch Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZd_A2zLHqjH"
      },
      "source": [
        "### Install Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2UwZR6jvONy"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovMIm1O4vPky"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxDOnc69vRTn"
      },
      "source": [
        "print(\"Cuda Current Device: \", torch.cuda.current_device())\n",
        "print(\"Cude Device Count: \", torch.cuda.device_count())\n",
        "print(\"Cude Device Name: \", torch.cuda.get_device_name(0))\n",
        "print(\"Cude Device Available : \", torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTXm_2dZh63x"
      },
      "source": [
        "### Basic Pytorch Operations (Optional, Backup)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj5zdxGUf6IH"
      },
      "source": [
        "# Create a Torch Vector\n",
        "a = [1, 2, 3]\n",
        "b = torch.Tensor(a)\n",
        "# b = torch.FloatTensor(a)\n",
        "# b = torch.DoubleTensor(a)\n",
        "# b = torch.IntTensor(a)\n",
        "# b = torch.LongTensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUoaYgJMFbIM"
      },
      "source": [
        "a = [1, 2, 3]\n",
        "b = torch.tensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQCPOCAf-i_"
      },
      "source": [
        "# Create a Torch Matrix\n",
        "a = [[1, 2, 3], [4, 5, 6]]\n",
        "b = torch.tensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XN85oeHgBb6"
      },
      "source": [
        "# Create a 3D Tensor\n",
        "a = [[[1., 2.], [3., 4.]],\n",
        "     [[5., 6.], [7., 8.]]]\n",
        "b = torch.tensor(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yOsyKiSgE3e"
      },
      "source": [
        "# Conversion from Tensor to numpy\n",
        "a = torch.tensor([3])\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jHE-i1znl7H"
      },
      "source": [
        "# Conversion from numpy to Tensor\n",
        "import numpy as np\n",
        "a = np.arange(6).reshape(2,3)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdBf5dyz13yv"
      },
      "source": [
        "# Numpy functions\n",
        "\n",
        "a = [1,2,3,4]\n",
        "b = np.array(a)\n",
        "c = np.sum(b)\n",
        "d = np.mean(b)\n",
        "e = np.max(b)\n",
        "print(c,d,e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2u2QLZnhXa6"
      },
      "source": [
        "# Torch functions\n",
        "a = [1.,2.,3.,4.]\n",
        "b = torch.tensor(a)\n",
        "c = torch.sum(b)\n",
        "d = torch.mean(b)\n",
        "e = torch.max(b)\n",
        "print(c,d,e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmI9Q9Ghh0my"
      },
      "source": [
        "# Tensor operations\n",
        "a = torch.tensor([1,1])\n",
        "b = torch.tensor([2,2])\n",
        "print(a+b)\n",
        "print(torch.add(a, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJCTD-SYbDy8"
      },
      "source": [
        "# Tensor operations with GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "a = torch.tensor([1,1]).to(device)\n",
        "b = torch.tensor([2,2]).to(device)\n",
        "c = a+b\n",
        "print(c)\n",
        "print(c.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRYeznRviUw0"
      },
      "source": [
        "# Activity: Tensor Operation with GPU\n",
        "a = torch.tensor([3]).to(device)\n",
        "b = torch.tensor([4]).to(device)\n",
        "c = torch.tensor([5]).to(device)\n",
        "d = a*b+c\n",
        "print(d)\n",
        "print(d.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6332HGEhcqc"
      },
      "source": [
        "# Torch matrix multiplication\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.mm(mat1, mat2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbdW_-ZSZtbQ"
      },
      "source": [
        "# Activity: Matrix operation\n",
        "x = torch.tensor([[1,1]])\n",
        "w = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[2,2]])\n",
        "print(torch.mm(x,w)+b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHLAtiyihloR"
      },
      "source": [
        "# Generate Special Torch Tensors\n",
        "a = torch.diag(torch.tensor([1,2,3]))\n",
        "a = torch.eye(3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsS5foAshq1P"
      },
      "source": [
        "# Torch linspace\n",
        "a = torch.linspace(1,10,10)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzI6VkgMhvvX"
      },
      "source": [
        "# Create uniform random numbers from 0 to 1\n",
        "a = torch.rand(5, 3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbWciFathsmL"
      },
      "source": [
        "# Create gaussion random numbers with mean 0 and std 1\n",
        "a = torch.randn(5, 3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjqGcmRfhoJF"
      },
      "source": [
        "# Torch Max\n",
        "a = torch.tensor([[1,0,0],[1,0,0],[0,1,0],[0,0,1]])\n",
        "print(torch.max(a,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLo86xlvK2Ll"
      },
      "source": [
        "# Activity: Torch Max\n",
        "a = torch.tensor([[3,4,-5,2,7,3]])\n",
        "torch.max(a,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCvcceTicor"
      },
      "source": [
        "# Reshape a torch tensor\n",
        "a = torch.linspace(1,10,10).view(2,5)\n",
        "a = torch.linspace(1,10,10).reshape(2,5)\n",
        "# a = torch.linspace(1,10,10).view(-1,2)\n",
        "# a = torch.linspace(1,10,10).reshape(-1,2)\n",
        "\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wWf1I4LucDs"
      },
      "source": [
        "# Unsqueeze and squeeze dimensions\n",
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=0) \n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdMoDX2g66fi"
      },
      "source": [
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=1) \n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8KgXNGtulXJ"
      },
      "source": [
        "# Concatenate\n",
        "x = torch.tensor([1,2,3])\n",
        "y = torch.cat((x,x,x))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZtHK1aupRa"
      },
      "source": [
        "# Transpose\n",
        "x = torch.tensor([[1,2],[3,4]])\n",
        "y = torch.t(x)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdb3LbkP5_Ut"
      },
      "source": [
        "# Activity: Tensor Operations\n",
        "\n",
        "x = torch.tensor([1,1])\n",
        "x = torch.unsqueeze(x,dim=0)\n",
        "#print(x.shape)\n",
        "w = torch.tensor([[1,2],[3,4]])\n",
        "#print(w.shape)\n",
        "b = torch.tensor([[2],[2]])\n",
        "b = torch.t(b)\n",
        "#print(b.shape)\n",
        "y = torch.mm(x,w)+b\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNhSJ6_zc4k"
      },
      "source": [
        "# Gradient and Back Propagation\n",
        "x = torch.tensor([5.],requires_grad=True)\n",
        "y = x*x\n",
        "y.backward()\n",
        "\n",
        "x.grad.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J18xNwP9Itkb"
      },
      "source": [
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "y = 2*x**2\n",
        "z = y**3\n",
        "\n",
        "z.backward()\n",
        "\n",
        "x.grad.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2zQAtwA0dHu"
      },
      "source": [
        "# Gradient\n",
        "x = torch.tensor([-2.], requires_grad=True)\n",
        "y = torch.tensor([5.],requires_grad=True)\n",
        "z = torch.tensor([-4.], requires_grad=True)\n",
        "f = (x+y)*z    \n",
        "\n",
        "f.backward()\n",
        "\n",
        "print('x gradient = ',x.grad.item())    \n",
        "print('y gradient = ',y.grad.item())     \n",
        "print('z gradient = ',z.grad.item())    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DXnhDc01YCJ"
      },
      "source": [
        "# Difference between .item and .data\n",
        "a = torch.randn(1)\n",
        "print(a.item())\n",
        "print(a.data)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x39nM7ndCrr"
      },
      "source": [
        "# Activity: Gradient\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "w = torch.tensor([3.], requires_grad=True)\n",
        "b = torch.tensor([4.], requires_grad=True)\n",
        "y = w*x + b    \n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print('x gradient = ', x.grad.item())     \n",
        "print('w gradient = ', w.grad.item())    \n",
        "print('b gradient = ', b.grad.item())\n",
        "\n",
        "# Print out the gradients.\n",
        "print('x gradient = ', x.grad)    \n",
        "print('w gradient = ', w.grad)\n",
        "print('b gradient = ', b.grad)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Um9tE0MJkJ5"
      },
      "source": [
        "# Activity: Compute Gradient\n",
        "x = torch.tensor([2.],requires_grad=True)\n",
        "w = torch.tensor([3.],requires_grad=True)\n",
        "b = torch.tensor([4.],requires_grad=True)\n",
        "y = w * x + b    \n",
        "\n",
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgjT09eoRh5S"
      },
      "source": [
        "# Activity: Compute Gradient\n",
        "\n",
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "y = 2*x**2\n",
        "z = y**3\n",
        "\n",
        "z.backward() #Computes the gradient \n",
        "print(x.grad.item()) #Print dz/dx "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPXRZX6ibWPJ"
      },
      "source": [
        "## Build a Regression Model Using NN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyAhWaDWMn8H"
      },
      "source": [
        "### Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFFQYaYJMj2P"
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "x = torch.linspace(-10,10,100)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "# Relu Activation Function\n",
        "x_relu = torch.relu(x)\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(x,x_relu)\n",
        "plt.title('relu')\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "x_sigmoid = torch.sigmoid(x)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(x,x_sigmoid)\n",
        "plt.title('sigmoid')\n",
        "\n",
        "# Hyperbolic Tanh Activation Function\n",
        "x_tanh = torch.tanh(x)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(x,x_tanh)\n",
        "plt.title('tanh')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1qhtFgjH0ml"
      },
      "source": [
        "### Simple Linear Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dbXJLdAb-Sn"
      },
      "source": [
        "# Step 1: Setup\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1.,2.,3,4,5])\n",
        "y = torch.tensor([0,-1.1,-1.8,-3.1,-4.5])\n",
        "\n",
        "W = torch.rand(1,requires_grad=True)\n",
        "b = torch.rand(1,requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_9eX4gdQjB"
      },
      "source": [
        "# Step 2: Optimizer\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD([W,b], lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q44h-938dTSq"
      },
      "source": [
        "# Step 3: Train the Model\n",
        "\n",
        "for i in range(1000):\n",
        "    # Model\n",
        "    yhat = X*W+b\n",
        "\n",
        "    # Loss Function\n",
        "    loss = (yhat-y).pow(2).sum()\n",
        "\n",
        "    #Compute gradient\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSZZUM_SGqWc"
      },
      "source": [
        "# Alternative Method using MSELoss method\n",
        "# Step 3: Train the Model\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for i in range(1000):\n",
        "    # Model\n",
        "    yhat = X*W+b\n",
        "\n",
        "    # Loss Function\n",
        "    loss = criterion(yhat,y)\n",
        "\n",
        "    #Compute gradient\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y2wvsDcNSif"
      },
      "source": [
        "# Step 4: Evaluate the Model\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "W_ = W.item()\n",
        "b_ = b.item()\n",
        "\n",
        "plt.plot(X,y,'o')\n",
        "plt.plot(X,X*W_+b_,'r')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz0EkmLtVTIn"
      },
      "source": [
        "# Explicit Zero Grad Demo\n",
        "# Without using optimizer\n",
        "\n",
        "import torch\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "X = torch.tensor([1.,2.,3,4,5])\n",
        "y = torch.tensor([0,-1.1,-1.8,-3.1,-4.5])\n",
        "\n",
        "W = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "for i in range(1000):\n",
        "    yhat = X*W+b\n",
        "\n",
        "    loss = (yhat - y).pow(2).sum()\n",
        "    loss.backward()\n",
        "\n",
        "    W.data -= learning_rate * W.grad.item()\n",
        "    b.data -= learning_rate * b.grad.item()\n",
        "\n",
        "    W.grad.data.zero_()\n",
        "    b.grad.data.zero_()\n",
        "    \n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjT2x8mSVlA6"
      },
      "source": [
        "# Step 4: Evaluate the Model\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "W_ = W.item()\n",
        "b_ = b.item()\n",
        "\n",
        "plt.plot(X,y,'o')\n",
        "plt.plot(X,X*W_+b_,'r')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwjxm4gH_Bf"
      },
      "source": [
        "### Neural Network Predictive Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUzOMUqcf-Gx"
      },
      "source": [
        "# Step 1: Setup\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1.,2.,3,4,5])\n",
        "y = torch.tensor([0,-1.1,-1.8,-3.1,-4.5])\n",
        "\n",
        "X = torch.unsqueeze(X, dim=1) \n",
        "y = torch.unsqueeze(y, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1whjKKHngXbV"
      },
      "source": [
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 3\n",
        "L2 = 5\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(1,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmexZ2HzkK_l"
      },
      "source": [
        "# Alternative way to define the model\n",
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 3\n",
        "L2 = 5\n",
        "\n",
        "model = nn.Sequential(nn.Linear(1, L1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L1, L2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L2, 1))\n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxjYOc2ZgbXO"
      },
      "source": [
        "# Step 3: Select Optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAz-OYUlgd0x"
      },
      "source": [
        "# Step 4: Training\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(X)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = (yhat - y).pow(2).sum()\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpBjV6GiggV8"
      },
      "source": [
        "# Step 5: Evaluate the Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X,y,'o')\n",
        "plt.plot(X,model(X).data,'r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtA2qbcygh6i"
      },
      "source": [
        "### Demo: Build a Predictive Regression Model for Housing Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LXn1ZVJIn_k"
      },
      "source": [
        "#### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns18cp-nepZ7"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/tertiarycourses/datasets/master/boston.csv\"                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRgXF8U5V-x"
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as-f5S9I5YN7"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9De5i0275Zzt"
      },
      "source": [
        "y_train = x_train.pop('medv')\n",
        "y_test = x_test.pop('medv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uO1NVtF5bOH"
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxTY-di5NHzS"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMx0mbe6wu5"
      },
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.Tensor(x_train.values)\n",
        "y_train = torch.Tensor(y_train.values)\n",
        "\n",
        "x_test = torch.Tensor(x_test.values)\n",
        "y_test = torch.Tensor(y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImdIPcDcGFAr"
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPMcsa5-HCs"
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So5PZ3YhIwzL"
      },
      "source": [
        "#### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItjYrsuu5dGc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(13,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9wclFVOI01a"
      },
      "source": [
        "#### Step 3 Define the Loss Function and Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3U04ACC6GNB"
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "criterion = nn.MSELoss()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OilVgBn66G9F"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBw7dlX6JPVG"
      },
      "source": [
        "#### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09vfhfgp6aI8"
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(yhat, y_train)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print(f'step {i}. loss = {loss.item():0.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjw3w75aLzN9"
      },
      "source": [
        "#### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEJZB0zH6l8_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, model(x_test).data)\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw3KpSEGA7Ty"
      },
      "source": [
        "y_hat.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XYniWyCOpji"
      },
      "source": [
        "### Save and Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkn0gAOtFiL1"
      },
      "source": [
        "torch.save(model,'./regression.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjuqTi1JNa7F"
      },
      "source": [
        "new_model=torch.load('./regression.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9OdIbhTOTcE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, new_model(x_test).data)\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvelV5hrO2kI"
      },
      "source": [
        "### Activity: Predictive Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04GMNiP-P5jD"
      },
      "source": [
        "### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGjfmx_YOW50"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/tertiarycourses/datasets/master/iris.csv\"\n",
        "                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD3hZcxpO7zp"
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.pop('species')\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHkS-SueO8Jl"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUPBVmV5O_9c"
      },
      "source": [
        "y_train = x_train.pop('sepal_width')\n",
        "y_test = x_test.pop('sepal_width')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCqBnnnpPHx0"
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGi64hZEPJqI"
      },
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.Tensor(x_train.values)\n",
        "y_train = torch.Tensor(y_train.values)\n",
        "\n",
        "x_test = torch.Tensor(x_test.values)\n",
        "y_test = torch.Tensor(y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey0ZAW46PRN6"
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtU9lexgPTCG"
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wNP54DhQF0_"
      },
      "source": [
        "### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2u3hPLPVEa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(3,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhE7L8cvQPz2"
      },
      "source": [
        "### Step 3 Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKRPul_HPZ6x"
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "criterion = nn.MSELoss()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIPapFsePen0"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZJ4DgwtQUhK"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsR_ml9SPhKZ"
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(yhat, y_train)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print(f'step {i}. loss = {loss.item():0.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIpnqun-Qhcw"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQRpr1_0Pjhj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, model(x_test).data)\n",
        "plt.xlabel('True Values Sepal Width')\n",
        "plt.ylabel('Predictions Sepal Width')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xVeTe7aRx89"
      },
      "source": [
        "## Build a Classification Model Using NN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cTyqPnmcBzS"
      },
      "source": [
        "### MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9dWS4jiwLT"
      },
      "source": [
        "#### Step 1: Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHeyy3IoSZPZ"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download MNIST training dataset and load training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download MNIST test dataset and load test data\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FLCSN0d5D-x"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image,label = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.title(\"Ground Truth: {}\".format(label[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9NXzwwdi3Lb"
      },
      "source": [
        "#### Step 2: Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWdKLPJWYRpF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)   \n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFJS0E2ql0aW"
      },
      "source": [
        "# Alternative way to define the model\n",
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "model = nn.Sequential(nn.Flatten(),\n",
        "                      nn.Linear(784, L1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L1, L2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L2, 10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y25GhcXtVq3f"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_zYqeegi-i6"
      },
      "source": [
        "#### Step 3: Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yE7i5cYRwD"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb7yPy8ui_7y"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3C_r1aUnxd4"
      },
      "source": [
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(testloader,1):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        loss = criterion(yhat,y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')        \n",
        "\n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYWNEQzzjDdx"
      },
      "source": [
        "#### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6VyVWK-sGkq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7wv4vI5eZjO"
      },
      "source": [
        "### Activity: Fashion MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n5DkX1IIDOV"
      },
      "source": [
        "#### Step 1: Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWqDZIRWedpx"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download FMNIST training dataset and load training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download FMNIST test dataset and load test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq5G4aLQuGgp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image,label = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.title(\"Ground Truth: {}\".format(label[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD736TNIIAkx"
      },
      "source": [
        "#### Step 2: Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgjTa0Qserd_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)   \n",
        "        return x\n",
        "\n",
        "model = Model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6NRPidnXmaH"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UGAZ04LIGaM"
      },
      "source": [
        "#### Step 3: Define the loss function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUfPP3Ee3ee"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F4s6VqdaGmT"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "306NmZEaUbIu"
      },
      "source": [
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(testloader,1):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        loss = criterion(yhat,y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')        \n",
        "    \n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j3uo7mRHyBU"
      },
      "source": [
        "#### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGNdB4pdE9R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kx1B_1KiGVz"
      },
      "source": [
        "# Topic 3 Recurrent Neural Network (RNN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2bmeqi8VidX"
      },
      "source": [
        "## LSTM and Input Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQIr3ycWbyOZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "number_layers = 1 #similar to hidden layers\n",
        "batch_size = 5\n",
        "input_size = 10 # similar to  embedding vector size to represent a word \n",
        "hidden_size = 20 # similar to hidden vector\n",
        "sequence_length = 3 # eg 3 words in a sequence or 3 days stock price data \n",
        "\n",
        "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=number_layers, batch_first=True)\n",
        "input = torch.randn(batch_size, sequence_length, input_size)\n",
        "h0 = torch.randn(number_layers, batch_size, hidden_size)\n",
        "_, hn = rnn(input, h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCPEPk8re2FR"
      },
      "source": [
        "input.shape, hn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc7UIm04kGF3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "number_layers = 1 #similar to hidden layers\n",
        "batch_size = 1 \n",
        "input_size = 10 # similar to  embedding vector size to represent a word \n",
        "hidden_size = 20 # similar to hidden vector\n",
        "sequence_length = 3 # # eg 3 words in a sequence or 3 days stock price dat\n",
        "\n",
        "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=number_layers, batch_first=False)\n",
        "input = torch.randn(sequence_length, batch_size, input_size)\n",
        "h0 = torch.randn(number_layers, batch_size, hidden_size)\n",
        "_, hn = rnn(input, h0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDUYDRhHkAJI"
      },
      "source": [
        "input.shape, hn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nn6iJExVg9k"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "number_layers = 1 #similar to hidden layers\n",
        "batch_size = 1 \n",
        "input_size = 10 # similar to  embedding vector size to represent a word \n",
        "hidden_size = 20 # similar to hidden vector\n",
        "sequence_length = 3 # eg 3 days stock price data \n",
        "\n",
        "rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=number_layers, batch_first=True)\n",
        "input = torch.randn(batch_size, sequence_length, input_size)\n",
        "h0 = torch.randn(number_layers, batch_size, hidden_size)\n",
        "c0 = torch.randn(number_layers, batch_size, hidden_size)\n",
        "_,(hn, cn) = rnn(input, (h0, c0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H56c4sfAtoZq"
      },
      "source": [
        "input.shape, hn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jsnrrnTuqZP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "number_layers = 1 #similar to hidden layers\n",
        "batch_size = 1 \n",
        "input_size = 10 # similar\n",
        " to  embedding vector size to represent a word \n",
        "hidden_size = 20 # similar to hidden vector\n",
        "sequence_length = 3 # eg 3 days stock price data \n",
        "\n",
        "rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=number_layers, batch_first=False)\n",
        "input = torch.randn(sequence_length, batch_size, input_size)\n",
        "h0 = torch.randn(number_layers, batch_size, hidden_size)\n",
        "c0 = torch.randn(number_layers, batch_size, hidden_size)\n",
        "_,(hn, cn) = rnn(input, (h0, c0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7cWg9eNuzj7"
      },
      "source": [
        "hn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiGxc0Cz0Owk"
      },
      "source": [
        "## RNN Demo (Airplane Passengers Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY66Xqlw08dt"
      },
      "source": [
        "### LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vyRveFTjWsv"
      },
      "source": [
        "#### Step 1: Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oAXrvtQoEdw"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nf8Bjrm90rZ"
      },
      "source": [
        "training_set = pd.read_csv('airline-passengers.csv')\n",
        "training_set.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhfkWWli-ACR"
      },
      "source": [
        "training_set.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAlA524g-R92"
      },
      "source": [
        "training_set = training_set.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(training_set, label = 'Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZMjqpDs-1rU"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXwv4zTUndJw"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(training_set)\n",
        "\n",
        "seq_length = 4\n",
        "x, y = sliding_window(training_data, seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuxtsGV0nbA8"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size\n",
        "\n",
        "dataX = torch.Tensor(np.array(x))\n",
        "dataY = torch.Tensor(np.array(y))\n",
        "\n",
        "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
        "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
        "\n",
        "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
        "testY = torch.Tensor(np.array(y[train_size:len(y)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7IFQywIVWTd"
      },
      "source": [
        "dataX.shape, trainX.shape, testX.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV-2363H4uRP"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb_hjukq-1Dq"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)       \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        _, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e23_U4qr9z8b"
      },
      "source": [
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "\n",
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_YfmD6K4w9T"
      },
      "source": [
        "#### Step 3: Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVCs2hLprLNJ"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = torch.nn.MSELoss()    \n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d15eK7p40K_"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATVFwxd3_59t"
      },
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = lstm(trainX)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, trainY)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3fjLDwhAIqk"
      },
      "source": [
        "#### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjX4fqMElHsj"
      },
      "source": [
        "lstm.eval()\n",
        "train_predict = lstm(dataX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(dataY_plot,'b',label='actual')\n",
        "plt.plot(data_predict,'r',label='prediction')\n",
        "plt.suptitle('Time Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxBNoYHFjZXt"
      },
      "source": [
        "### GRU Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pGYGqcM1GMW"
      },
      "source": [
        "#### Step 1: Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1ICd91ojUgQ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC_ouacHjpYg"
      },
      "source": [
        "training_set = pd.read_csv('airline-passengers.csv')\n",
        "training_set.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68aaS3cHj01a"
      },
      "source": [
        "training_set = training_set.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(training_set, label = 'Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY_ZGVgDj4OQ"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyLUdXoLj8n2"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(training_set)\n",
        "\n",
        "seq_length = 4\n",
        "x, y = sliding_window(training_data, seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TTjSuMfkArb"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size\n",
        "\n",
        "dataX = torch.Tensor(np.array(x))\n",
        "dataY = torch.Tensor(np.array(y))\n",
        "\n",
        "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
        "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
        "\n",
        "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
        "testY = torch.Tensor(np.array(y[train_size:len(y)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yipimPwa1Jnk"
      },
      "source": [
        "#### Step 2:  Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEFgnZ7UkHEg"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(GRU, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        _, h_out = self.gru(x, h_0)\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iCixrFykSSP"
      },
      "source": [
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "\n",
        "gru = GRU(num_classes, input_size, hidden_size, num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "891iGNG91Nog"
      },
      "source": [
        "#### Step 3: Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlPXP3Z4kda_"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = torch.nn.MSELoss()    \n",
        "optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTZ16cQw1RRt"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Su8Jamoklrh"
      },
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = gru(trainX)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, trainY)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhtbz_8I1T_R"
      },
      "source": [
        "#### Step 4:  Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ExSzSwkk3fg"
      },
      "source": [
        "gru.eval()\n",
        "train_predict = gru(dataX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(dataY_plot,'b',label='actual')\n",
        "plt.plot(data_predict,'r',label='prediction')\n",
        "plt.suptitle('Time Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGSeTI-vlDrz"
      },
      "source": [
        "### RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtJWB17b1aNf"
      },
      "source": [
        "#### Step 1: Prepare the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVSzOORblFxL"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7_Y50lslLH7"
      },
      "source": [
        "training_set = pd.read_csv('airline-passengers.csv')\n",
        "training_set.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYAQ_MYzliVg"
      },
      "source": [
        "training_set = training_set.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(training_set, label = 'Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bX6siATlMHp"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7QipMd9lRbO"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(training_set)\n",
        "\n",
        "seq_length = 4\n",
        "x, y = sliding_window(training_data, seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8jN1vuillnv"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size\n",
        "\n",
        "dataX = torch.Tensor(np.array(x))\n",
        "dataY = torch.Tensor(np.array(y))\n",
        "\n",
        "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
        "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
        "\n",
        "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
        "testY = torch.Tensor(np.array(y[train_size:len(y)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLzK9sBc1doQ"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QW5SCOIluO_"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        _, h_out = self.rnn(x, h_0)\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zLQS_eXlzJJ"
      },
      "source": [
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "\n",
        "rnn = RNN(num_classes, input_size, hidden_size, num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhzPuMSl1gpm"
      },
      "source": [
        "#### Step 3: Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARsplch4l3_3"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = torch.nn.MSELoss()    \n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON__dUmp1jwY"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_02LH4Fzl8CH"
      },
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = rnn(trainX)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, trainY)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhmsFW5P1nza"
      },
      "source": [
        "#### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdhiYzp3mCB9"
      },
      "source": [
        "rnn.eval()\n",
        "train_predict = rnn(dataX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(dataY_plot,'b',label='actual')\n",
        "plt.plot(data_predict,'r',label='prediction')\n",
        "plt.suptitle('Time Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H977BgUKNauY"
      },
      "source": [
        "## Activity: LSTM for Shampoo Sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlktYiwTCQYR"
      },
      "source": [
        "### Step 1: Load Data (Shampoo Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cQZO2EzBHF9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXiUmPswNiM6"
      },
      "source": [
        "training_set = pd.read_csv('shampoo.csv')\n",
        "training_set.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rnd-Wu_OCSj"
      },
      "source": [
        "training_set.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbt2CqDyOFwQ"
      },
      "source": [
        "training_set = training_set.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(training_set, label = 'Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys8iPIbsPzwe"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPpQGMqY_QQ2"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(training_set)\n",
        "\n",
        "seq_length = 3\n",
        "x, y = sliding_window(training_data, seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18fpKwmb_X_n"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size\n",
        "\n",
        "dataX = torch.Tensor(np.array(x))\n",
        "dataY = torch.Tensor(np.array(y))\n",
        "\n",
        "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
        "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
        "\n",
        "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
        "testY = torch.Tensor(np.array(y[train_size:len(y)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBCHPcovCVij"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpWXlhDTP6Tm"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        _, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoEQWUrtm7VJ"
      },
      "source": [
        "input_size = 1\n",
        "hidden_size = 3\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "\n",
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bedyjo_PCX29"
      },
      "source": [
        "### Step 3: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usxuFhNpB9e2"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = torch.nn.MSELoss()    \n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C57Pga1Ca9F"
      },
      "source": [
        "### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCduyUf9CBq-"
      },
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = lstm(trainX)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, trainY)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgX0pQEMCecn"
      },
      "source": [
        "### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4b3w2jGCEiT"
      },
      "source": [
        "lstm.eval()\n",
        "train_predict = lstm(dataX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(dataY_plot,'b',label='actual')\n",
        "plt.plot(data_predict,'r',label='prediction')\n",
        "plt.suptitle('Time Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a891-NPTGvJX"
      },
      "source": [
        "## Activity: Stock Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft4q5pr81-qQ"
      },
      "source": [
        "### Step 1: Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-cyjXSyCKQ9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ROM_-S5G1nW"
      },
      "source": [
        "training_set = pd.read_csv('AAPL.csv',usecols=['Date','Close'])\n",
        "training_set.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu1wwh4YG84O"
      },
      "source": [
        "training_set.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE5VonSuG_N8"
      },
      "source": [
        "training_set = training_set.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(training_set, label = 'Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFc3Gj3fHN8p"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCe10sfMHRRv"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(training_set)\n",
        "\n",
        "seq_length = 4\n",
        "x, y = sliding_window(training_data, seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gggOOGkkHVkx"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size\n",
        "\n",
        "dataX = torch.Tensor(np.array(x))\n",
        "dataY = torch.Tensor(np.array(y))\n",
        "\n",
        "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
        "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
        "\n",
        "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
        "testY = torch.Tensor(np.array(y[train_size:len(y)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajk-vSO42CQ5"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1hqTl5wHd6f"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        _, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzd4IxfRHhQw"
      },
      "source": [
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "\n",
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aB7MYfg2FHS"
      },
      "source": [
        "### Step 3: Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWOoI7eUHku6"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = torch.nn.MSELoss()    \n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_yVjaUU2I4G"
      },
      "source": [
        "### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k7XbwQPHn_C"
      },
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = lstm(trainX)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, trainY)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42s0MWGm2Lez"
      },
      "source": [
        "### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4THpKiQHsVh"
      },
      "source": [
        "lstm.eval()\n",
        "train_predict = lstm(dataX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(dataY_plot,'b',label='actual')\n",
        "plt.plot(data_predict,'r',label='prediction')\n",
        "plt.suptitle('Time Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8r1cBM8zb2e"
      },
      "source": [
        "## Text Classificaiton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSwx_QKPEBMH"
      },
      "source": [
        "### Step 1: Import IMDN Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nELMLmczYVm"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQdSkFVCDamS"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcCxd5FaDf7Q"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBol-JBkEYca"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct_1B4WxEiYs"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjzbII9RE6Ph"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xshE76K8FJQ_"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B4AHYGLFcah"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA4eBoOZHAKs"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "trainloader, validloader, testloader = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozYdnTeaHo1n"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThHquhhDHBST"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):       \n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)    \n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)    \n",
        "        output, h_out = self.gru(embedded)       \n",
        "        assert torch.equal(output[-1,:,:], h_out.squeeze(0))\n",
        "        return self.fc(h_out.squeeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW0deDNNI1MF"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = GRU(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYlbPLt0KOYL"
      },
      "source": [
        "### Step 3: Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWTFyScnKGAT"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxAntTWJKdJ7"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd_KTsUEnwn7"
      },
      "source": [
        "def train():\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for (X,y) in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        yhat = model(X).squeeze(1)\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWlnTSWjn1bN"
      },
      "source": [
        "def evaluate():\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (X,y) in validloader:\n",
        "            yhat = model(X).squeeze(1)\n",
        "            loss = criterion(yhat, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            preds = torch.round(torch.sigmoid(yhat))\n",
        "            correct = (preds == y)\n",
        "            acc = correct.sum() / len(y)\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(validloader), epoch_acc / len(validloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MEKXZL9ykWi"
      },
      "source": [
        "def test():\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (X,y) in testloader:\n",
        "            yhat = model(X).squeeze(1)\n",
        "            loss = criterion(yhat, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            preds = torch.round(torch.sigmoid(yhat))\n",
        "            correct = (preds == y)\n",
        "            acc = correct.sum() / len(y)\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(testloader), epoch_acc / len(testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9QHJfFBn9tl"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train()\n",
        "    valid_loss, valid_acc = evaluate()\n",
        "\n",
        "    print(f'Epoch: {epoch+1} Train Loss: {train_loss:.3f} | Val Loss: {valid_loss:.3f} |  Val Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izOsDiDd3rON"
      },
      "source": [
        "### Step 5 Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSlRCXS6LUS3"
      },
      "source": [
        "test_loss, test_acc = test()\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kze0f3VXjIFa"
      },
      "source": [
        "# Topic 4 Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rND43YsX2fZH"
      },
      "source": [
        "## MNIST Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfVmcqnUdW43"
      },
      "source": [
        "### Step 1: Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBkzWrbudI8V"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cezdjeMTu45G"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean, std)])\n",
        "\n",
        "# Download MNIST training dataset and load training data\n",
        "trainset = datasets.MNIST('MNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download MNIST test dataset and load test data\n",
        "testset = datasets.MNIST('MNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzufVUondZt4"
      },
      "source": [
        "### Step 2: Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaur5V-uTpQc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,L1,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(L1,L2,3,1,1)\n",
        "        self.fc1 = nn.Linear(L2*7*7,L3)\n",
        "        self.fc2 = nn.Linear(L3, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lppROK-HpB3L"
      },
      "source": [
        "# Alternative way to define the model\n",
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "model = nn.Sequential(nn.Conv2d(1,L1,3,1,1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(2),\n",
        "                      nn.Conv2d(L1,L2,3,1,1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(2),\n",
        "                      nn.Flatten(),\n",
        "                      nn.Linear(L2*7*7,L3),\n",
        "                      nn.Linear(L3, 10))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9x9EeyPErpr"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPipBlT6bC1i"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LMjouRZdb_o"
      },
      "source": [
        "### Step 3: Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8lKoivsVE2a"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-1pch4dehW"
      },
      "source": [
        "### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9yMLMhJUqms"
      },
      "source": [
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for (X, y) in trainloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (X, y) in testloader:            \n",
        "            yhat = model(X)\n",
        "            loss = criterion(yhat,y)\n",
        "            test_loss += loss.item()\n",
        "            \n",
        "            _, pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "    \n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')    \n",
        "\n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxGU64eydj2E"
      },
      "source": [
        "### Step 5: Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6f0sEAbLw6B"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RIGyBLzdtGt"
      },
      "source": [
        "## Activity: CNN on CIFAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E56-2QeE2-Rh"
      },
      "source": [
        "### Step 1: Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koAag2qVd3S6"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='CIFAR10/',train=True, download=True,transform=transform)\n",
        "testset = datasets.CIFAR10(root='CIFAR10/',train=False, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPS4YytD3B7u"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNUZsHqOd60G"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,L1,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(L1,L2,3,1,1)\n",
        "        self.fc1 = nn.Linear(L2*8*8,L3)\n",
        "        self.fc2 = nn.Linear(L3, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyXCRcqscmWJ"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvpHWIzZ3FYV"
      },
      "source": [
        "### Step 3: Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcQiiffzd_WG"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiuTGxri3H7V"
      },
      "source": [
        "### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJoRh0ueKHo"
      },
      "source": [
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for (X, y) in trainloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in testloader:        \n",
        "            yhat = model(X)\n",
        "            loss = criterion(yhat,y)\n",
        "            test_loss += loss.item()\n",
        "            \n",
        "            _, pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')   \n",
        "\n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NiQQGAL3L94"
      },
      "source": [
        "### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Qq3sQdeNpS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6UqVuxePtA2"
      },
      "source": [
        "## Techniques to Resolve Overfitting Issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpZfExS30OLc"
      },
      "source": [
        "### Baseline wihtout Data Augmentatin and Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYTNjZgGH7nZ"
      },
      "source": [
        "#### Step 1: Load Small Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHgvw8egr56T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKCNcKrlxxIn"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1oqO4zNZyLc"
      },
      "source": [
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1QVyG7_Kxh3"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/dataset/hymenoptera_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUkcA6uoK1a7"
      },
      "source": [
        "trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms['train'])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "testset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transforms['val'])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4je-a0ynOzjh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def denormalize(tensor):\n",
        "  tensor = tensor*std+ mean\n",
        "  return tensor\n",
        "\n",
        "def show_img(img):\n",
        "  img = img.numpy().transpose((1,2,0))\n",
        "  img = denormalize(img)\n",
        "  img = np.clip(img,0,1)\n",
        "  plt.imshow(img)\n",
        "\n",
        "def get_class(id):\n",
        "  classes = ['ant', 'bee']\n",
        "  return classes[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhX5NgkPMlA7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRRyxFt_CtF_"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7cf5JpyI20D"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwJhW18ezgp0"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LruwfDzIAWsc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,L1,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(L1,L2,3,1,1)\n",
        "        self.fc1 = nn.Linear(L2*56*56,L3)\n",
        "        self.fc2 = nn.Linear(L3, 2)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ner3DJtjL4P-"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC469hoCzow4"
      },
      "source": [
        "#### Step 3: Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FAon_AlAcCi"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBfgv53ZJ50y"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmgvsYMdzshN"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i37apPuKA3o6"
      },
      "source": [
        "num_epochs = 15\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    model.train()\n",
        "    for (X, y) in trainloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in testloader:         \n",
        "            yhat = model(X)\n",
        "            loss = criterion(yhat,y)\n",
        "            test_loss += loss.item()\n",
        "            \n",
        "            _, pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')   \n",
        "\n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naTagyiR0DKW"
      },
      "source": [
        "#### Step 5: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd40II-WFBAj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1BKtKGxRx8w"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(testloader))\n",
        "output = model(images)\n",
        "_,pred = torch.max(output,1)\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i])+\"/\"+get_class(pred[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTr-gKHhZKSJ"
      },
      "source": [
        "### Data Augmentation and Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Quh4WG0c17"
      },
      "source": [
        "#### Step 1: Load the Small Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq1eaPMIZfX3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al1Nac-ZZJPi"
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),                         \n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZCu__WtZZuM"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/dataset/hymenoptera_data'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpkfdt3eZqCw"
      },
      "source": [
        "trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms['train'])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "testset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transforms['val'])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuKubxA_aMme"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def denormalize(tensor):\n",
        "  tensor = tensor*std+ mean\n",
        "  return tensor\n",
        "\n",
        "def show_img(img):\n",
        "  img = img.numpy().transpose((1,2,0))\n",
        "  img = denormalize(img)\n",
        "  img = np.clip(img,0,1)\n",
        "  plt.imshow(img)\n",
        "\n",
        "def get_class(id):\n",
        "  classes = ['ant', 'bee']\n",
        "  return classes[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksp_nwDQaYjH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6Sw7HCj0j-9"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MflZzD36anMv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,L1,3,1,1)\n",
        "        self.d1 = nn.Dropout(0.2)\n",
        "        self.conv2 = nn.Conv2d(L1,L2,3,1,1)\n",
        "        self.fc1 = nn.Linear(L2*56*56,L3)\n",
        "        self.fc2 = nn.Linear(L3, 2)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = self.d1(x) \n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        \n",
        "        x = F.relu(self.fc1(x))             \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylf8fhs7aa62"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQwEIzR-0nKQ"
      },
      "source": [
        "#### Step 3: Loss Function and Optimzer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHFA7P5JbpWu"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOid3MRI0tUI"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXLzd6jsbzDE"
      },
      "source": [
        "num_epochs = 15\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    model.train()\n",
        "    for (X, y) in trainloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in testloader:\n",
        "            \n",
        "            yhat = model(X)\n",
        "            loss = criterion(yhat,y)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            \n",
        "            _, pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            num_correct += (pred == y.data).sum()\n",
        "        \n",
        "        test_tracker.append(test_loss/len(testloader))\n",
        "        print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "        accuracy_tracker.append(num_correct/total)\n",
        "        print(f'Accuracy : {num_correct/total}')   \n",
        "\n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvAa07hl0wGy"
      },
      "source": [
        "#### Step 5: Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpfe50BgeyCs"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Db0HwASfDYi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(testloader))\n",
        "output = model(images)\n",
        "_,pred = torch.max(output,1)\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i])+\"/\"+get_class(pred[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcbo4QZ4QASi"
      },
      "source": [
        "# Topic 5 Application of Machine Learning to Signal Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7aEqiF-ZeXo"
      },
      "source": [
        "## Load Pre-Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lac7pM46ZVJc"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiZfetQEZn6H"
      },
      "source": [
        "## Load Test Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpJ7n7AQZm27"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = 'cat.jpg'\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "img = Image.open(image_path)\n",
        "img_tensor = preprocess(img)\n",
        "img_tensor = img_tensor.unsqueeze_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsuJuMxJa5-_"
      },
      "source": [
        "import requests\n",
        "\n",
        "LABELS_URL = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
        "labels = {int(key):value for (key, value) in requests.get(LABELS_URL).json().items()}\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmRDM7alehjF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predict = model(img_tensor)\n",
        "\n",
        "print(labels[predict.data.numpy().argmax()])\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoVphpNFdPEE"
      },
      "source": [
        "## Activity: Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piNvsCqodVN1"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czWDJm1ae17I"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = 'elephant.jpg'\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "img = Image.open(image_path)\n",
        "img_tensor = preprocess(img)\n",
        "img_tensor = img_tensor.unsqueeze_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-GU1v2_e6AC"
      },
      "source": [
        "import requests\n",
        "\n",
        "LABELS_URL = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
        "labels = {int(key):value for (key, value) in requests.get(LABELS_URL).json().items()}\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3xk80TWe_Fk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predict = model(img_tensor)\n",
        "\n",
        "print(labels[predict.data.numpy().argmax()])\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0jNuC3mttxb"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKhx-10x1lOY"
      },
      "source": [
        "### Step 1: Load the Small Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yEki83u1XtA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Orqp7y1dyi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1VcHqau1sqH"
      },
      "source": [
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIcNYM2d10CY"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/dataset/hymenoptera_data'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dihVsoX919W6"
      },
      "source": [
        "trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms['train'])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "testset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transforms['val'])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvvtTnrT2EF6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def denormalize(tensor):\n",
        "  tensor = tensor*std+ mean\n",
        "  return tensor\n",
        "\n",
        "def show_img(img):\n",
        "  img = img.numpy().transpose((1,2,0))\n",
        "  img = denormalize(img)\n",
        "  img = np.clip(img,0,1)\n",
        "  plt.imshow(img)\n",
        "\n",
        "def get_class(id):\n",
        "  classes = ['ant', 'bee']\n",
        "  return classes[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPfalM9u2Ida"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbN6vAWJ1yvc"
      },
      "source": [
        "### Step 2: Load the Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmu3dWzG9mlF"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp8g6D76110Y"
      },
      "source": [
        "### Model Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7P3sqyk52B4"
      },
      "source": [
        "model.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn1r0rdi16Nk"
      },
      "source": [
        "### Step 3: Replace Classifier and Output layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bvW2LAj_L-C"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZDkiWZD6Qc-"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrCfP0WV6TN5"
      },
      "source": [
        "model.classifier[-1] = nn.Sequential(\n",
        "                       nn.Linear(in_features=4096, out_features=10)\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZNx2maZ6mYo"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOmxuc8U1-Ca"
      },
      "source": [
        "### Add GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noJsmtKW_qVi"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_a4gqjD2AFn"
      },
      "source": [
        "### Step 4: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXU9joNG7BPb"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()                           \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yba6aninfPv"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYqPvaTQ2E86"
      },
      "source": [
        "### Step 5: Re-train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhOj83AKxS3M"
      },
      "source": [
        "from tqdm.notebook import trange,tqdm\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "for i in trange(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for (X, y) in tqdm(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        yhat = model(X)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss  += loss.item()\n",
        "    \n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnrxwBIF2LD2"
      },
      "source": [
        "### Step 6: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beHSFKES7Fgl"
      },
      "source": [
        "from tqdm.notebook import trange,tqdm\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for (X,y) in tqdm(testloader):\n",
        "        \n",
        "        yhat = model(X)\n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-uq5-PH8Ut3"
      },
      "source": [
        "### Step 7: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjpC7tGP4qAg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(testloader))\n",
        "output = model(images)\n",
        "_,pred = torch.max(output,1)\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i])+\"/\"+get_class(pred[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C73hu1qc7iR"
      },
      "source": [
        "## Fine Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s7_2a2Y2hXt"
      },
      "source": [
        "### Step 1: Load the Small Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ13ccmUVbPu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNbGmzd75pAB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ2eueDp5uIp"
      },
      "source": [
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ]),\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_K6Rsuo5y_A"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/dataset/hymenoptera_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGtmj9kM50kT"
      },
      "source": [
        "trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms['train'])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "testset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transforms['val'])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3PSlIS5540Q"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def denormalize(tensor):\n",
        "  tensor = tensor*std+ mean\n",
        "  return tensor\n",
        "\n",
        "def show_img(img):\n",
        "  img = img.numpy().transpose((1,2,0))\n",
        "  img = denormalize(img)\n",
        "  img = np.clip(img,0,1)\n",
        "  plt.imshow(img)\n",
        "\n",
        "def get_class(id):\n",
        "  classes = ['ant', 'bee']\n",
        "  return classes[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgwYG3jA6BvJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJFsYai52jtL"
      },
      "source": [
        "### Step 2: Load the pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djYrT-Ojf5Yq"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34EU5nfG2p2O"
      },
      "source": [
        "### Step 3: Unfreeze Model Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T9jIivzoVcl"
      },
      "source": [
        "model.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XedVK3baBgrR"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKOW1KI0Bkf0"
      },
      "source": [
        "for i in range(24,31):\n",
        "  model.features[i].requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr49Dcgq2x08"
      },
      "source": [
        "### Step 4: Replace Model Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGBL4PeGBim8"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MMm2WoLBmdj"
      },
      "source": [
        "model.classifier[-1] = nn.Sequential(\n",
        "                       nn.Linear(in_features=4096, out_features=10)\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb7OgbgRBpz2"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naVYZeLk20kA"
      },
      "source": [
        "### Add GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxxKh6kwB2rt"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqZD4UMf3J_Z"
      },
      "source": [
        "### Step 5: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daPq1-uICCLt"
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()                           \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI-eNdyV3NBI"
      },
      "source": [
        "### Step 6:Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5ABrxuhn41"
      },
      "source": [
        "from tqdm.notebook import trange,tqdm\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "for i in trange(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for (X, y) in tqdm(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        yhat = model(X)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss  += loss.item()\n",
        "    \n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bc6MDcJ3PdG"
      },
      "source": [
        "### Step 7: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lastLvP3w3ZY"
      },
      "source": [
        "from tqdm.notebook import trange,tqdm\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for (X,y) in tqdm(testloader):\n",
        "        \n",
        "        yhat = model(X)\n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO2JFMcy3R5w"
      },
      "source": [
        "### Step 8:Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8EfbHmehpvi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images,labels = next(iter(testloader))\n",
        "output = model(images)\n",
        "_,pred = torch.max(output,1)\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  show_img(images[i])\n",
        "  plt.title(get_class(labels[i])+\"/\"+get_class(pred[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Y6WCD-7z--"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}